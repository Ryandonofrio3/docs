---
title: OpenAI
description: Auto-trace OpenAI API calls
---

# OpenAI Integration

Automatically trace all OpenAI API calls with zero code changes to your existing implementation.

## Supported APIs

| API | Streaming | Tool Calls | Token Counting |
|-----|-----------|------------|----------------|
| Chat Completions | Yes | Yes | Yes |
| Responses API | Yes | Yes | Yes |

## TypeScript

```bash
bun add rd-mini openai
```

```typescript
import { Raindrop } from 'rd-mini';
import OpenAI from 'openai';

const raindrop = new Raindrop({ apiKey: process.env.RAINDROP_API_KEY });
const openai = raindrop.wrap(new OpenAI());

// Non-streaming
const response = await openai.chat.completions.create({
  model: 'gpt-4o',
  messages: [{ role: 'user', content: 'Hello!' }],
});

console.log(response._traceId); // Access trace ID
```

### Streaming

```typescript
const stream = await openai.chat.completions.create({
  model: 'gpt-4o',
  messages: [{ role: 'user', content: 'Write a poem' }],
  stream: true,
});

console.log(stream._traceId); // Available immediately

for await (const chunk of stream) {
  process.stdout.write(chunk.choices[0]?.delta?.content || '');
}
// Trace is automatically completed when stream ends
```

### Tool Calls

```typescript
const response = await openai.chat.completions.create({
  model: 'gpt-4o',
  messages: [{ role: 'user', content: 'What is the weather in SF?' }],
  tools: [
    {
      type: 'function',
      function: {
        name: 'get_weather',
        description: 'Get the weather',
        parameters: {
          type: 'object',
          properties: { location: { type: 'string' } },
          required: ['location'],
        },
      },
    },
  ],
});

// Tool calls are automatically captured in the trace
```

### Per-Request Options

```typescript
const response = await openai.chat.completions.create(
  {
    model: 'gpt-4o',
    messages: [{ role: 'user', content: 'Hello!' }],
  },
  {
    raindrop: {
      userId: 'user_123',
      conversationId: 'conv_456',
      properties: { experiment: 'v2' },
    },
  }
);
```

## Python

```bash
uv add rd-mini openai
```

```python
from raindrop import Raindrop
from openai import OpenAI

raindrop = Raindrop(api_key=os.environ["RAINDROP_API_KEY"])
openai = raindrop.wrap(OpenAI())

# Non-streaming
response = openai.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Hello!"}],
)

print(response._trace_id)  # Access trace ID
```

### Streaming

```python
stream = openai.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Write a poem"}],
    stream=True,
)

for chunk in stream:
    print(chunk.choices[0].delta.content or "", end="")
# Trace is automatically completed when stream ends
```

### Per-Request Options

```python
response = openai.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Hello!"}],
    raindrop={
        "user_id": "user_123",
        "conversation_id": "conv_456",
        "properties": {"experiment": "v2"},
    },
)
```

## What's Captured

Every OpenAI call automatically captures:

- **Model** - Which model was used
- **Input** - Messages sent to the model
- **Output** - Model's response (including streamed content)
- **Tokens** - Input, output, and total token counts
- **Latency** - Time from request to response
- **Tool Calls** - Function names and arguments
- **Errors** - Any errors that occurred

## Responses API

The new OpenAI Responses API is also supported:

```typescript
const response = await openai.responses.create({
  model: 'gpt-4o',
  input: 'Hello!',
});

console.log(response._traceId);
```
